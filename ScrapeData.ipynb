{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa0f834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup as bs4\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a1e350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ScrapeSongsOfYear(YearSongsURL):\n",
    "    page = requests.get(YearSongsURL)\n",
    "    soup = bs4(page.content, 'html.parser')\n",
    "    section = soup.find(class_='mw-parser-output')\n",
    "    table = section.find('table',{\"class\":\"wikitable sortable\"}) #specific table\n",
    "    body = table.find('tbody')\n",
    "    rows = body.find_all('tr')\n",
    "    row = body.find_all('td')\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eacef872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractData(data):\n",
    "    df = pd.DataFrame(columns=[\"Index\",\"Song\",\"Artist\",\"Genre\"])\n",
    "    links = []\n",
    "    titleAndName = []\n",
    "    \n",
    "    for row in data:\n",
    "        link_elem = row.find('a')\n",
    "        info = row.get_text().strip()\n",
    "        titleAndName.append(info)\n",
    "        if link_elem is None: \n",
    "            links.append(\"NoneType\") # If no link on artist/song\n",
    "        else:\n",
    "            link = link_elem.get('href')\n",
    "            links.append(\"https://en.wikipedia.org\"+link)\n",
    "    \n",
    "    df[\"Index\"]= titleAndName[::3]\n",
    "    df[\"Song\"]=titleAndName[1::3]\n",
    "    df[\"Artist\"]=titleAndName[2::3]\n",
    "    \n",
    "    songlink = links[1::3]\n",
    "    artistlink = links[2::3]\n",
    "\n",
    "    return df,songlink,artistlink\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d69876f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/angeleparkcollin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#extract just the pronouns from a text\n",
    "nltk.download('punkt') # download the necessary nltk data\n",
    "\n",
    "def extract_pronouns(text):\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    \n",
    "    # Use nltk's POS tagging to tag the parts of speech in each sentence\n",
    "    tagged_sentences = [nltk.pos_tag(nltk.word_tokenize(sentence)) for sentence in sentences]\n",
    "    \n",
    "    # Extract the pronouns from the tagged sentences\n",
    "    pronouns = []\n",
    "    for tagged_sentence in tagged_sentences:\n",
    "        for word, pos in tagged_sentence:\n",
    "#             print(word,pos)\n",
    "            if pos == 'PRP' or pos == 'PRP$' or word == \"band\" or word==\"collaboration\":\n",
    "                pronouns.append(word.lower())\n",
    "    \n",
    "    keep_list =['she','her','band','collaboration','him','his','he']\n",
    "    for p in pronouns:\n",
    "        if p not in keep_list:\n",
    "            pronouns.remove(p)\n",
    "    \n",
    "    return pronouns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78b2b37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getArtistGender(links):\n",
    "    genders =[]\n",
    "    for link in links:\n",
    "        if link == \"NoneType\": # ie. No link\n",
    "            genders.append('Unknown')\n",
    "            continue\n",
    "        page = requests.get(link)\n",
    "        soup = bs4(page.content, 'html.parser')\n",
    "        section = soup.find(class_='mw-body-content mw-content-ltr')\n",
    "\n",
    "        intro = section.find_all('p')[1].text\n",
    "        \n",
    "        if len(intro) < 5:\n",
    "            intro = section.find_all('p')[2].text\n",
    "        pronouns = extract_pronouns(intro)\n",
    "        if len(pronouns) == 0:\n",
    "            pronouns = ['Unknown']\n",
    "        \n",
    "        if pronouns[0] == \"she\" or pronouns[0] == \"her\":\n",
    "            genders.append('Female')\n",
    "        elif pronouns[0] == \"his\" or pronouns[0] == \"him\" or pronouns[0]== 'he':\n",
    "            genders.append('Male')\n",
    "        elif pronouns[0] =='band' or pronouns[0] =='collaboration'or pronouns[0] =='group':\n",
    "            genders.append('Group')\n",
    "        else:\n",
    "            genders.append('Unknown')\n",
    "\n",
    "    return genders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a28ab7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSongGenre(links, df, start_index=0):\n",
    "    for link in links:\n",
    "        if link == \"NoneType\": # ie. No link\n",
    "            df.loc[start_index, \"Genre\"] = \"None\"\n",
    "            continue\n",
    "        page = requests.get(link)\n",
    "        soup = bs4(page.content, 'html.parser')\n",
    "        table = soup.find('table', class_='infobox').find('th', string='Genre') \n",
    "        if table is None:\n",
    "            df.loc[start_index, \"Genre\"] = \"None\"\n",
    "        else:\n",
    "            genres = table.find_parent('tr').find('td')\n",
    "            genre_names = [genre.strip() for genre in genres.text.split('\\n') if genre.strip()]\n",
    "            superscript_pattern = r'\\[\\d+\\]'\n",
    "            genre_names = [re.sub(superscript_pattern, '', text) for text in genre_names]\n",
    "            df.loc[start_index, \"Genre\"] = genre_names[0]\n",
    "            \n",
    "        start_index += 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d68e6993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSongGenre(links, df, start_index=0):\n",
    "    for link in links:\n",
    "        if link == \"NoneType\": # ie. No link\n",
    "            df.loc[start_index, \"Genre\"] = \"None\"\n",
    "            continue\n",
    "        page = requests.get(link)\n",
    "        soup = bs4(page.content, 'html.parser')\n",
    "        table = soup.find('table', class_='infobox')\n",
    "        if table is None:\n",
    "            df.loc[start_index, \"Genre\"] = \"None\"\n",
    "        else:\n",
    "            box = table.find('th', string='Genre') \n",
    "            if box is None:\n",
    "                df.loc[start_index, \"Genre\"] = \"None\"\n",
    "            else:\n",
    "                genres = box.find_parent('tr').find('td')\n",
    "                genre_names = [genre.strip() for genre in genres.text.split('\\n') if genre.strip()]\n",
    "                superscript_pattern = r'\\[\\d+\\]'\n",
    "                genre_names = [re.sub(superscript_pattern, '', text) for text in genre_names]\n",
    "                df.loc[start_index, \"Genre\"] = genre_names[0]\n",
    "            \n",
    "        start_index += 1\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "62a24a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSongGenre(links, df, start_index=0):\n",
    "    for link in links:\n",
    "        if link == \"NoneType\": # ie. No link\n",
    "            df.loc[start_index, \"Genre\"] = \"None\"\n",
    "            start_index += 1\n",
    "            continue\n",
    "        page = requests.get(link)\n",
    "        soup = bs4(page.content, 'html.parser')\n",
    "        table = soup.find('table', class_='infobox')\n",
    "        if table is None:\n",
    "            df.loc[start_index, \"Genre\"] = \"None\"\n",
    "        else:\n",
    "            box = table.find('th', string='Genre') \n",
    "            if box is None:\n",
    "                df.loc[start_index, \"Genre\"] = \"None\"\n",
    "            else:\n",
    "                genres = box.find_parent('tr').find('td')\n",
    "                genre_names = [genre.strip() for genre in genres.text.split('\\n') if genre.strip()]\n",
    "                superscript_pattern = r'\\[\\d+\\]'\n",
    "                genre_names = [re.sub(superscript_pattern, '', text) for text in genre_names]\n",
    "                df.loc[start_index, \"Genre\"] = genre_names[0]\n",
    "            \n",
    "        start_index += 1\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a336365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapre from wikipedia\n",
    "Y2022=\"https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_2022\" #100\n",
    "Y2012=\"https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_2012\" #100\n",
    "Y2002=\"https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_2002\" #100\n",
    "Y1992=\"https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_1992\" #100\n",
    "Y1982=\"https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_1982\" #100\n",
    "Y1972=\"https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_1972\" #100\n",
    "Y1962=\"https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_1962\" #100\n",
    "Y1952=\"https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_1952\" #30\n",
    "Y1946=\"https://en.wikipedia.org/wiki/Billboard_year-end_top_singles_of_1946\" #35\n",
    "years = [Y2022,Y2012,Y2002,Y1992,Y1982,Y1972,Y1962,Y1952,Y1946]\n",
    "for year in years:\n",
    "    data = ScrapeSongsOfYear(Y1946)\n",
    "    df,songlinks,artistlink = ExtractData(data)\n",
    "    genders = getArtistGender(artistlink)\n",
    "    df['Genders'] = pd.Series(genders)\n",
    "    getSongGenre(songlinks,df)\n",
    "\n",
    "    #     Put df into csv file\n",
    "    df.to_csv('songsOfYear.csv', mode='a', index=False, header=False)\n",
    "# Will take a while to run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b51487",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kero",
   "language": "python",
   "name": "kero"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
